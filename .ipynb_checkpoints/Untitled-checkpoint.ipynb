{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_labels : ['motorbike', 'airplane']\n",
      "train_x shape: (12288, 1500)\n",
      "train_y shape: (1, 1500)\n",
      "test_x shape : (12288, 100)\n",
      "test_y shape : (1, 100)\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ravishen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: RuntimeWarning: divide by zero encountered in log\n",
      "/home/ravishen/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......................................................................................................................................................................................................train_accuracy: 100.0 %\n",
      "test_accuracy : 98.0 %\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  0. 0. 0. 0.]]\n",
      "[[-0.03375174]\n",
      " [-0.01487486]\n",
      " [ 0.01211567]\n",
      " ...\n",
      " [-0.02582544]\n",
      " [-0.01879706]\n",
      " [-0.00630893]]\n",
      "-0.008749853803949234\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from keras.preprocessing import image\n",
    "import h5py\n",
    "\n",
    "train_path = \"/home/ravishen/Desktop/ml_course/deepLearning/dataset/train\"\n",
    "test_path = \"/home/ravishen/Desktop/ml_course/deepLearning/dataset/test\"\n",
    "\n",
    "train_labels = os.listdir(train_path)\n",
    "test_labels = os.listdir(test_path)\n",
    "\n",
    "img_size = (64,64)\n",
    "no_of_train_img = 1500 #750+750\n",
    "no_of_test_img = 100 #50+50\n",
    "no_of_channel = 3\n",
    "\n",
    "train_x = np.zeros(((img_size[0]*img_size[1]*no_of_channel),no_of_train_img))\n",
    "train_y = np.zeros((1,no_of_train_img))\n",
    "\n",
    "\n",
    "test_x = np.zeros(((img_size[0]*img_size[1]*no_of_channel),no_of_test_img))\n",
    "test_y = np.zeros((1,no_of_test_img))\n",
    "\n",
    "\n",
    "num_label =0\n",
    "count =0\n",
    "\n",
    "for i,label in enumerate(train_labels):\n",
    "    cur_path = train_path+ \"/\" +label\n",
    "    for img_path in glob.glob(cur_path+\"/*.jpg\"):\n",
    "        img = image.load_img(img_path,target_size=img_size)\n",
    "        x = image.img_to_array(img)\n",
    "        x= x.flatten()\n",
    "        #x = np.expand_dims(x,axis=0)\n",
    "        train_x[:,count]= x\n",
    "        train_y[:,count] = num_label\n",
    "        count+=1\n",
    "    num_label+=1\n",
    " \n",
    "count =0\n",
    "num_label =0\n",
    "for i,label in enumerate(test_labels):\n",
    "    cur_path = test_path+ \"/\" +label\n",
    "    for img_path in glob.glob(cur_path+\"/*.jpg\"):\n",
    "        img = image.load_img(img_path,target_size=img_size)\n",
    "        x = image.img_to_array(img)\n",
    "        x= x.flatten()\n",
    "        #x = np.expand_dims(x,axis=0)\n",
    "        test_x[:,count]= x\n",
    "        test_y[:,count] = num_label\n",
    "        count+=1\n",
    "    num_label+=1\n",
    " \n",
    "    \n",
    " #standardization\n",
    "train_x = train_x/255\n",
    "test_x = test_x/255\n",
    "\n",
    "print (\"train_labels : \" + str(train_labels))\n",
    "print (\"train_x shape: \" + str(train_x.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x shape : \" + str(test_x.shape))\n",
    "print (\"test_y shape : \" + str(test_y.shape))\n",
    "\n",
    "#saving dataset\n",
    "h5_train = h5py.File(\"train_x.h5\",'w')\n",
    "h5_train.create_dataset(\"data_train\", data=np.array(train_x))\n",
    "h5_train.close()\n",
    "\n",
    "h5_test = h5py.File(\"test_x.h5\",'w')\n",
    "h5_test.create_dataset(\"data_test\", data=np.array(test_x))\n",
    "h5_test.close()\n",
    "\n",
    "def sigmoid(z):\n",
    "    return (1/(1+np.exp(-z)))\n",
    "\n",
    "def init_params(dimension):\n",
    "    w = np.zeros((dimension, 1))\n",
    "    b = 0\n",
    "    return w, b\n",
    "\n",
    "def propogate(w,b,X,Y):\n",
    "    m= X.shape[1]\n",
    "    \n",
    "    A = sigmoid(np.dot(w.T,X) + b)\n",
    "    cost = (-1/m)*(np.sum(np.multiply(Y,np.log(A)) + np.multiply((1-Y),np.log(1-A))))\n",
    "    dw = (1/m)*(np.dot(X, (A-Y).T))\n",
    "    db = (1/m)*(np.sum(A-Y))\n",
    "    #cost = np.squeeze(cost)\n",
    "    \n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    return grads, cost\n",
    "\n",
    "\n",
    "def optimize(w,b,X,Y,epochs,lr):\n",
    "    costs =[]\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        grads,cost = propogate(w,b,X,Y)\n",
    "        \n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        \n",
    "        w = w - (lr*dw)\n",
    "        b = b - (lr*db)\n",
    "        \n",
    "        if i%10== 0:\n",
    "            print (\".\",end=\"\", flush=True)\n",
    "        \n",
    "    params = {\"w\": w, \"b\": b}\n",
    "\n",
    "    grads  = {\"dw\": dw, \"db\": db}\n",
    "\n",
    "    return params, grads, costs\n",
    "\n",
    "\n",
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    Y_predict = np.zeros((1,m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0, i] <= 0.5:\n",
    "            Y_predict[0, i] = 0\n",
    "        else:\n",
    "            Y_predict[0,i]  = 1\n",
    "\n",
    "    return Y_predict\n",
    "\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, epochs, lr):\n",
    "    w, b = init_params(X_train.shape[0])\n",
    "    params, grads, costs = optimize(w, b, X_train, Y_train, epochs, lr)\n",
    "\n",
    "    w = params[\"w\"]\n",
    "    b = params[\"b\"]\n",
    "\n",
    "    Y_predict_train = predict(w, b, X_train)\n",
    "    Y_predict_test  = predict(w, b, X_test)\n",
    "    \n",
    "    print (\"train_accuracy: {} %\".format(100-np.mean(np.abs(Y_predict_train - Y_train)) * 100))\n",
    "    print (\"test_accuracy : {} %\".format(100-np.mean(np.abs(Y_predict_test  - Y_test)) * 100))\n",
    "\n",
    "    log_reg_model = {\"costs\": costs,\n",
    "                \"Y_predict_test\": Y_predict_test, \"Y_predict_train\" : Y_predict_train, \"w\" : w, \"b\" : b,\"learning_rate\" : lr,\"epochs\": epochs}\n",
    "\n",
    "    return log_reg_model\n",
    "\n",
    "epochs = 2000\n",
    "lr = 0.1\n",
    "\n",
    "\n",
    "myModel = model(train_x, train_y, test_x, test_y, epochs, lr)\n",
    "print(myModel['Y_predict_test'])\n",
    "print(myModel['w'])\n",
    "print(myModel['b'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_web_image(url):\n",
    "    name = \"image\"\n",
    "    full_name = name+\".jpg\"\n",
    "    urllib.request.urlretrieve(url,full_name)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_web_image(\"https://www.daronwwt.com/cataloglarge/bp201.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_image = cv2.imread('image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('sample image',read_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad argument type for built-in operation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-07cccdc4d22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: bad argument type for built-in operation"
     ]
    }
   ],
   "source": [
    "\n",
    "resized_image = cv2.resize(, (64, 64)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
